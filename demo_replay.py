#!/usr/bin/env python3
"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–ø–∏—Å–∏ –∏ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è SMAC replay
"""

import os
import sys
from pathlib import Path
import yaml
import torch
import numpy as np
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ PyMARL –≤ sys.path
PYMARL_PATH = str(Path(__file__).resolve().parent / "pymarl" / "src")
if PYMARL_PATH not in sys.path:
    sys.path.append(PYMARL_PATH)

from smac.env import StarCraft2Env
from core.amal_agent import AMALAgent

class SMACReplayWrapper:
    """SMAC Wrapper —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π replay"""
    
    def __init__(self, scenario_name: str, seed: int = None, 
                 replay_dir: str = None, replay_prefix: str = None):
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è replay
        if replay_dir is None:
            replay_dir = os.path.join(os.getcwd(), "replays")
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        os.makedirs(replay_dir, exist_ok=True)
        
        if replay_prefix is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            replay_prefix = f"{scenario_name}_{timestamp}"
        
        print(f"üé¨ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ replay:")
        print(f"  –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {replay_dir}")
        print(f"  –ü—Ä–µ—Ñ–∏–∫—Å: {replay_prefix}")
        
        try:
            self.env = StarCraft2Env(
                map_name=scenario_name, 
                seed=seed,
                replay_dir=replay_dir,
                replay_prefix=replay_prefix
            )
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ SMAC –¥–ª—è '{scenario_name}': {e}")
            raise e
            
        self.env_info = self.env.get_env_info()
        self.n_agents = self.env_info["n_agents"]
        self.obs_dim = self.env_info["obs_shape"]
        self.state_dim = self.env_info["state_shape"]
        self.action_dim = self.env_info["n_actions"]
        self.episode_limit = self.env_info["episode_limit"]
        
        print(f"‚úÖ SMAC Replay Wrapper –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è: {scenario_name}")
        print(f"   –ê–≥–µ–Ω—Ç—ã: {self.n_agents}, Obs: {self.obs_dim}, State: {self.state_dim}, Actions: {self.action_dim}")
    
    def reset(self):
        self.env.reset()
        obs_list = self.env.get_obs()
        state = self.env.get_state()
        return {i: np.array(obs_list[i]) for i in range(self.n_agents)}, np.array(state)
    
    def step(self, actions):
        action_list = [actions.get(i, 0) for i in range(self.n_agents)]
        reward, done, info = self.env.step(action_list)
        next_obs_list = self.env.get_obs()
        next_state = self.env.get_state()
        return {i: np.array(next_obs_list[i]) for i in range(self.n_agents)}, np.array(next_state), reward, done, info
    
    def get_available_actions(self):
        avail_actions_list = self.env.get_avail_actions()
        return {i: np.array(avail_actions_list[i]) for i in range(self.n_agents)}
    
    def save_replay(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç replay —Ç–µ–∫—É—â–µ–≥–æ —ç–ø–∏–∑–æ–¥–∞"""
        try:
            self.env.save_replay()
            print("‚úÖ Replay —Å–æ—Ö—Ä–∞–Ω–µ–Ω!")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è replay: {e}")
            return False
    
    def close(self):
        self.env.close()

def demo_replay_episode():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ —ç–ø–∏–∑–æ–¥–∞ —Å –∑–∞–ø–∏—Å—å—é replay"""
    
    print("üéÆ === –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø REPLAY –í SMAC ===")
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    scenario = "2s_vs_1sc"
    replay_dir = "replays"
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    replay_prefix = f"amal_demo_{timestamp}"
    
    # –°–æ–∑–¥–∞–µ–º environment —Å replay
    env = SMACReplayWrapper(
        scenario_name=scenario,
        seed=42,
        replay_dir=replay_dir,
        replay_prefix=replay_prefix
    )
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–µ–Ω–Ω—É—é AMAL –º–æ–¥–µ–ª—å
    with open('configs/amal_config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    agent = AMALAgent(
        n_agents=env.n_agents,
        obs_dim=env.obs_dim,
        state_dim=env.state_dim,
        action_dim=env.action_dim,
        config=config['algorithm'],
        device='cuda' if torch.cuda.is_available() else 'cpu'
    )
    
    # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
    try:
        agent.load('models/amal_2s_vs_1sc_e100.pt')
        print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –æ–±—É—á–µ–Ω–Ω–∞—è AMAL –º–æ–¥–µ–ª—å")
        use_trained = True
    except:
        print("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω—É—é –ø–æ–ª–∏—Ç–∏–∫—É")
        use_trained = False
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —ç–ø–∏–∑–æ–¥
    obs, state = env.reset()
    done = False
    episode_reward = 0
    episode_steps = 0
    
    print(f"\nüéØ –ù–∞—á–∏–Ω–∞–µ–º —ç–ø–∏–∑–æ–¥...")
    print(f"–¶–µ–ª—å: –∑–∞–ø–∏—Å—å –¥–µ–π—Å—Ç–≤–∏–π –∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
    
    while not done and episode_steps < env.episode_limit:
        avail_actions = env.get_available_actions()
        
        if use_trained:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
            actions, info = agent.select_actions(obs, state, avail_actions, explore=False)
        else:
            # –°–ª—É—á–∞–π–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö
            actions = {}
            for i in range(env.n_agents):
                avail_indices = np.where(avail_actions[i] == 1)[0]
                if len(avail_indices) > 0:
                    actions[i] = np.random.choice(avail_indices)
                else:
                    actions[i] = 0
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º —à–∞–≥
        next_obs, next_state, reward, done, env_info = env.step(actions)
        
        episode_reward += reward
        episode_steps += 1
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–µ 10 —à–∞–≥–æ–≤
        if episode_steps % 10 == 0:
            print(f"  –®–∞–≥ {episode_steps}: Actions={actions}, Reward={reward:.2f}")
        
        obs, state = next_obs, next_state
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º replay
    replay_saved = env.save_replay()
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–ø–∏–∑–æ–¥–∞:")
    print(f"  –®–∞–≥–æ–≤: {episode_steps}")
    print(f"  –û–±—â–∏–π reward: {episode_reward:.2f}")
    print(f"  –ü–æ–±–µ–¥–∞: {env_info.get('battle_won', False)}")
    print(f"  Replay —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {replay_saved}")
    
    if replay_saved:
        replay_path = os.path.join(replay_dir, f"{replay_prefix}.SC2Replay")
        print(f"  üìÅ –§–∞–π–ª replay: {replay_path}")
        print(f"\nüé¨ –ö–∞–∫ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å replay:")
        print(f"  1. –û—Ç–∫—Ä–æ–π—Ç–µ StarCraft II")
        print(f"  2. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ —Ä–∞–∑–¥–µ–ª 'Replays'")
        print(f"  3. –ù–∞–π–¥–∏—Ç–µ —Ñ–∞–π–ª: {replay_prefix}.SC2Replay")
        print(f"  4. –ò–ª–∏ —Å–∫–æ–ø–∏—Ä—É–π—Ç–µ –≤ ~/Documents/StarCraft II/Accounts/*/Replays/")
    
    env.close()
    return replay_saved, episode_reward, episode_steps

if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫–∞–µ–º –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—é
    try:
        replay_saved, reward, steps = demo_replay_episode()
        
        print(f"\nüéâ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print(f"Replay –∑–∞–ø–∏—Å–∞–Ω: {replay_saved}")
        if replay_saved:
            print(f"\nüí° –¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ:")
            print(f"  - –ü—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å replay –≤ StarCraft II")
            print(f"  - –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ–≤–µ–¥–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤")
            print(f"  - –ü–æ–Ω—è—Ç—å, –ø–æ—á–µ–º—É AMAL –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏: {e}")
        import traceback
        traceback.print_exc()
